{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7_PA03GbeyIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anatomy of the Model"
      ],
      "metadata": {
        "id": "ZNP3CvLjeyS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required packages"
      ],
      "metadata": {
        "id": "SHFmRS8zeyVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install flax"
      ],
      "metadata": {
        "id": "Q30A61o_e4Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the imports"
      ],
      "metadata": {
        "id": "ji1Y9b6efPGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "from typing import Any, Callable\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "EtWrCIJde4W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model signature"
      ],
      "metadata": {
        "id": "PuFX0VcgfZyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ f(w; x) = \\hat{y} $$\n",
        "We place parameters at the first place to match the signature required later by JAX."
      ],
      "metadata": {
        "id": "XxPDzUYrcHGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3gD_xPgzqDN"
      },
      "outputs": [],
      "source": [
        "# Linear Regression\n",
        "np.random.seed(1337)\n",
        "\n",
        "def predict(w, x):\n",
        "  # y = w.T @ x\n",
        "  y = np.sum(w * x)\n",
        "  return y\n",
        "\n",
        "\n",
        "params = np.ones(5)\n",
        "\n",
        "# features, batch of data\n",
        "x = np.array([1] + [2, 3, 7, 2])\n",
        "\n",
        "# output\n",
        "y = predict(params, x)\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP model signature"
      ],
      "metadata": {
        "id": "5FvWhS_odj-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-layer Dense network"
      ],
      "metadata": {
        "id": "_PZy-DdU3zJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(W, b, x):\n",
        "    z = W @ x + b   # Linear transformation\n",
        "    a = np.maximum(0, z)  # ReLU activation\n",
        "    return a\n",
        "\n",
        "input_dim = 4  # Input features\n",
        "output_dim = 1  # Number of output neurons\n",
        "\n",
        "x = np.array([2, 3, 7, 2])\n",
        "\n",
        "W = np.ones((output_dim, input_dim))  # Initialize weights with all 1s\n",
        "b = np.ones(output_dim, )  # Initialize biases with all 1s\n",
        "\n",
        "y = predict(W, b, x)\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "v4A9AReadi7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why JAX?"
      ],
      "metadata": {
        "id": "6j1Moeo0djkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In ML, we need more than a forward pass:\n",
        "\n",
        "* Compute **gradients** of a loss\n",
        "* Run efficiently on **GPU/TPU**\n",
        "* Batch inputs\n",
        "* Compile for speed\n",
        "\n",
        "NumPy alone won‚Äôt cover this stack.\n",
        "\n",
        "JAX extends the NumPy programming model with *program transformations*:\n",
        "\n",
        "| We write | JAX gives |\n",
        "| -------- | --------- |\n",
        "| `f(x)`   | `grad(f)` |\n",
        "| `f(x)`   | `jit(f)`  |\n",
        "| `f(x)`   | `vmap(f)` |\n",
        "\n",
        "We don't just evaluate functions - we **transform functions into new functions**.\n",
        "\n",
        "Mental model: **JAX = NumPy + autodiff + XLA compilation + vectorization** üöÄ\n",
        "But beware of the sharp edges: [https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "t9sOACdgvpfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "import jax\n",
        "\n",
        "def predict(W, b, x):\n",
        "    z = W @ x + b  # Linear transformation\n",
        "    a = jnp.maximum(0, z)  # ReLU activation\n",
        "    return a\n",
        "\n",
        "input_dim = 4\n",
        "output_dim = 1\n",
        "\n",
        "W = jnp.ones((output_dim, input_dim))\n",
        "b = jnp.ones((output_dim, ))\n",
        "\n",
        "x = jnp.array([2, 3, 7, 2])\n",
        "\n",
        "y = predict(W, b, x)\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "id": "zwTRI_SLeY_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now compare with jitted version."
      ],
      "metadata": {
        "id": "wT75ZmhVxDmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we jit!\n",
        "jitted_predict = jax.jit(predict)"
      ],
      "metadata": {
        "id": "qJYZL5kzxtUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# --- setup ---\n",
        "input_dim, output_dim = 4, 1\n",
        "W = jnp.ones((output_dim, input_dim))\n",
        "b = jnp.ones((output_dim,))\n",
        "x = jnp.array([2, 3, 7, 2])\n",
        "\n",
        "# --- warmup (compilation happens here) ---\n",
        "y0 = jitted_predict(W, b, x).block_until_ready()\n",
        "\n",
        "# --- timing helpers ---\n",
        "def time_call(f, n=1_000):\n",
        "    # run once to avoid first-call overhead (except compilation, already done above)\n",
        "    f(W, b, x).block_until_ready()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    for _ in range(n):\n",
        "        y = f(W, b, x)\n",
        "    y.block_until_ready()  # sync once at end (important on GPU/async backends)\n",
        "    t1 = time.perf_counter()\n",
        "    return (t1 - t0) / n\n",
        "\n",
        "t_eager = time_call(predict)\n",
        "t_jit   = time_call(jitted_predict)\n",
        "\n",
        "print(f\"eager avg: {t_eager*1e6:.2f} microsec /call\")\n",
        "print(f\"jit   avg: {t_jit*1e6:.2f} microsec /call\")\n",
        "print(f\"speedup: {t_eager/t_jit:.1f}x\")"
      ],
      "metadata": {
        "id": "MU6VWFrBwy1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No backward pass written manually.\n",
        "No gradient accumulation stored in parameters.\n",
        "Just **pure functions + transformations**."
      ],
      "metadata": {
        "id": "VLTncbJ_xzN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why Flax?"
      ],
      "metadata": {
        "id": "h8JF7HT8usHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "JAX gives us transformations.\n",
        "\n",
        "But building large neural networks directly in raw JAX quickly becomes messy:\n",
        "\n",
        "* Where do parameters live?\n",
        "* How do we initialize them?\n",
        "* How do we manage dropout RNG?\n",
        "* How do we save / load models?\n",
        "\n",
        "Flax solves this."
      ],
      "metadata": {
        "id": "wK5Ob7IqeooE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flax is a **neural network library built on JAX**.\n",
        "\n",
        "It gives:\n",
        "\n",
        "* Structured modules (`nn.Module`)\n",
        "* Parameter initialization via `.init()`\n",
        "* Explicit parameter passing via `.apply()`\n",
        "* Clean parameter trees (pytrees)\n",
        "* Compatibility with `grad`, `jit`, `vmap`\n"
      ],
      "metadata": {
        "id": "Hk_TV4BVyA2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key design principle: in Flax, a model is still a **pure function**.\n",
        "\n",
        "Model API:\n",
        "\n",
        "1Ô∏è‚É£ **Define the model** (`nn.Module`, (optionally) with `setup()`)  \n",
        "2Ô∏è‚É£ **Initialize parameters** (`model.init()`)  \n",
        "3Ô∏è‚É£ **Run inference** (`model.apply()`)  \n"
      ],
      "metadata": {
        "id": "m6uWuQ3eeSsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradients are obtained by differentiating a loss built from `.apply()`."
      ],
      "metadata": {
        "id": "XnKXCQ5WyQNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flax.linen as nn\n",
        "\n",
        "class VanillaMLP(nn.Module):\n",
        "    output_dim: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        # linear layer\n",
        "        x = nn.Dense(\n",
        "            self.output_dim,\n",
        "            kernel_init=nn.initializers.ones,\n",
        "            bias_init=nn.initializers.ones,\n",
        "        )(x)\n",
        "\n",
        "        # activation function\n",
        "        x = nn.relu(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "HojXQSOg5X24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 4\n",
        "output_dim = 1\n",
        "\n",
        "x = jnp.array([2, 3, 7, 2])\n",
        "\n",
        "model = VanillaMLP(output_dim=output_dim)\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "params = model.init(key, jnp.ones(input_dim))"
      ],
      "metadata": {
        "id": "JBtBouok0Zdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax.core import freeze, unfreeze\n",
        "\n",
        "print(jax.tree_util.tree_map(lambda x: x.shape, params))"
      ],
      "metadata": {
        "id": "iV0OGe3v0ab3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model.apply(params, x)\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "id": "e5Rl7r0e0d9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary: NumPy -> JAX -> Flax\n",
        "\n",
        "Your NumPy model:\n",
        "\n",
        "* Computes a forward pass\n",
        "\n",
        "JAX:\n",
        "\n",
        "* Makes it differentiable and fast\n",
        "\n",
        "Flax:\n",
        "\n",
        "* Makes it scalable and maintainable\n",
        "\n",
        "Together, they let us build research-grade training pipelines üöÄ"
      ],
      "metadata": {
        "id": "uOcEzQYPuzlM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bookkeeping"
      ],
      "metadata": {
        "id": "_DFwnwGN6NSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **Flax**, model parameters (`params`) are stored as a **frozen dictionary (`FrozenDict`)**, which can be **saved and loaded** using JAX serialization tools like `flax.serialization.to_bytes()` and `flax.serialization.from_bytes()`, or `pickle`/`json` for more flexibility.\n",
        "\n",
        "**1Ô∏è‚É£ Save Model Weights to a File**\n",
        "```python\n",
        "import flax\n",
        "import pickle\n",
        "\n",
        "# Save params to a file (binary format)\n",
        "with open(\"model_params.pkl\", \"wb\") as f:\n",
        "    pickle.dump(flax.serialization.to_bytes(params), f)\n",
        "```\n",
        "\n",
        "**2Ô∏è‚É£ Load Model Weights from a File**\n",
        "```python\n",
        "# Load params from file\n",
        "with open(\"model_params.pkl\", \"rb\") as f:\n",
        "    params_loaded = flax.serialization.from_bytes(params, pickle.load(f))\n",
        "\n",
        "print(\"Loaded Parameters:\", params_loaded)\n",
        "```\n"
      ],
      "metadata": {
        "id": "mho3hfCK6WSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"model_params.pkl\", \"wb\") as f:\n",
        "    pickle.dump(flax.serialization.to_bytes(params), f)"
      ],
      "metadata": {
        "id": "DwjJjWBP6OA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"model_params.pkl\", \"rb\") as f:\n",
        "    params_loaded = flax.serialization.from_bytes(params, pickle.load(f))"
      ],
      "metadata": {
        "id": "Kw2tk4gg66ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference again\n",
        "y = model.apply(params_loaded, x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "ZCyYTikz6-bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-trained Models"
      ],
      "metadata": {
        "id": "y6IlJXPFfhjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional: this is HuggingFace in PyTorch for inference only; training in this course is JAX/Flax."
      ],
      "metadata": {
        "id": "HTK_6KzXtthn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install transformers"
      ],
      "metadata": {
        "id": "TlezWjuDg8IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "import requests\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "\n",
        "# Fetch and display the image\n",
        "response = requests.get(url)\n",
        "img = PILImage.open(BytesIO(response.content))\n",
        "display(img)"
      ],
      "metadata": {
        "id": "k6hCY3_1hVHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: ViT https://huggingface.co/docs/transformers/en/model_doc/vit\n",
        "\n",
        "Trained on ImageNet: https://paperswithcode.com/dataset/imagenet"
      ],
      "metadata": {
        "id": "86mm3ZGWh7iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTImageProcessor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Get the image from the web\n",
        "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Load preprocessor and model\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "# Run the inference engine\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "cyrdfTv-fgpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(outputs)"
      ],
      "metadata": {
        "id": "5380FLb0ievU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs.logits\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "ydlrYzCiic5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-1\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "NPY75QFvf_5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Get the top-10 predictions\n",
        "top_10 = torch.topk(logits, 10)\n",
        "\n",
        "# Extract top indices and their corresponding scores\n",
        "top_10_indices = top_10.indices[0].tolist()\n",
        "top_10_scores = top_10.values[0].tolist()\n",
        "\n",
        "# Display results\n",
        "print(\"Top-10 Predicted Classes:\")\n",
        "for rank, (idx, score) in enumerate(zip(top_10_indices, top_10_scores), start=1):\n",
        "    print(f\"{rank}. {model.config.id2label[idx]} ({score:.4f})\")"
      ],
      "metadata": {
        "id": "S6mB2Koaiwz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}